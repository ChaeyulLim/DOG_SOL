# 12_STORAGE ëª¨ë“ˆ ì™„ë²½ í•¨ìˆ˜ ëª…ì„¸ì„œ v2.0 (ê°œì„ íŒ)

> **ê°œì„ ì‚¬í•­**: ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ëª…ì„œì—ì„œ **ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥í•œ í•¨ìˆ˜ ëª…ì„¸ì„œ**ë¡œ ì™„ì „ ë³€í™˜

---

## ğŸ“‹ ëª©ì°¨
1. [storage/historical_manager.py](#storagehistorical_managerpy) â­ ì‹ ê·œ
2. [storage/cache_manager.py](#storagecache_managerpy) â­ ì‹ ê·œ
3. [storage/state_manager.py](#storagestate_managerpy) â­ ì‹ ê·œ
4. [storage/cleanup.py](#storagecleanuppy) â­ ì‹ ê·œ
5. [ì „ì²´ ì˜ì¡´ì„± ê·¸ë˜í”„](#ì „ì²´-ì˜ì¡´ì„±-ê·¸ë˜í”„)
6. [ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ](#ì‹¤ì „-ì‚¬ìš©-ì˜ˆì œ)

---

## ğŸ“ storage/historical_manager.py â­ ì‹ ê·œ

### êµ¬í˜„ ì½”ë“œ (ì „ì²´ ì‹ ê·œ)

```python
import ccxt
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict
from core.constants import HISTORICAL_DATA_DIR


class HistoricalDataManager:
    """
    ë°±í…ŒìŠ¤íŠ¸ìš© ê³¼ê±° ë°ì´í„° ê´€ë¦¬
    
    â­ ì‹ ê·œ ëª¨ë“ˆ: ê³¼ê±° ë°ì´í„° ë‹¤ìš´ë¡œë“œ, ê²€ì¦, ë¡œë“œ
    """
    
    def __init__(self):
        """
        ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        í˜¸ì¶œ:
            scripts/download_historical_data.py
            engine/backtest_engine.py
        """
        self.data_dir = Path(HISTORICAL_DATA_DIR)
        self.data_dir.mkdir(parents=True, exist_ok=True)
    
    def download_historical_data(
        self,
        symbol: str,
        timeframe: str = '5m',
        days: int = 180
    ) -> bool:
        """
        Bybit APIë¡œ ê³¼ê±° ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        
        Args:
            symbol: 'DOGE/USDT', 'SOL/USDT'
            timeframe: '1m', '5m', '15m', '1h', '1d'
            days: ë‹¤ìš´ë¡œë“œ ì¼ìˆ˜ (ê¸°ë³¸ 180ì¼ = 6ê°œì›”)
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        
        í˜¸ì¶œ:
            scripts/download_historical_data.py
        
        Example:
            >>> manager = HistoricalDataManager()
            >>> success = manager.download_historical_data('DOGE/USDT', '5m', 180)
            ë‹¤ìš´ë¡œë“œ ì¤‘: DOGE/USDT 5m (180ì¼)
            ì§„í–‰: 1000/51840 ìº”ë“¤
            ì§„í–‰: 2000/51840 ìº”ë“¤
            ...
            âœ… DOGE_USDT_5m.csv ì €ì¥ ì™„ë£Œ (51840ê°œ)
        """
        print(f"ë‹¤ìš´ë¡œë“œ ì¤‘: {symbol} {timeframe} ({days}ì¼)")
        
        try:
            exchange = ccxt.bybit()
            
            # ì‹œì‘ ì‹œê°„
            since = exchange.parse8601(
                (datetime.now() - timedelta(days=days)).isoformat()
            )
            
            all_ohlcv = []
            
            while True:
                ohlcv = exchange.fetch_ohlcv(
                    symbol,
                    timeframe,
                    since=since,
                    limit=1000
                )
                
                if not ohlcv:
                    break
                
                all_ohlcv.extend(ohlcv)
                since = ohlcv[-1][0] + 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if len(all_ohlcv) % 1000 == 0:
                    print(f"ì§„í–‰: {len(all_ohlcv)} ìº”ë“¤")
                
                if len(ohlcv) < 1000:
                    break
            
            if not all_ohlcv:
                print(f"âŒ ë°ì´í„° ì—†ìŒ: {symbol}")
                return False
            
            # DataFrame ë³€í™˜
            df = pd.DataFrame(
                all_ohlcv,
                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
            )
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
            df['timestamp'] = df['timestamp'] // 1000
            
            # íŒŒì¼ëª…
            filename = f"{symbol.replace('/', '_')}_{timeframe}.csv"
            filepath = self.data_dir / filename
            
            # CSV ì €ì¥
            df.to_csv(filepath, index=False)
            
            print(f"âœ… {filename} ì €ì¥ ì™„ë£Œ ({len(df)}ê°œ)")
            return True
        
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def validate_csv(self, filepath: str) -> Dict:
        """
        CSV ë°ì´í„° ê²€ì¦
        
        Args:
            filepath: CSV íŒŒì¼ ê²½ë¡œ
        
        Returns:
            {
                'valid': bool,
                'errors': List[str],
                'count': int,
                'start_date': str,
                'end_date': str
            }
        
        í˜¸ì¶œ:
            scripts/validate_historical_data.py
        
        Example:
            >>> manager = HistoricalDataManager()
            >>> result = manager.validate_csv('storage/historical/DOGE_USDT_5m.csv')
            >>> if result['valid']:
            >>>     print(f"ê²€ì¦ ì„±ê³µ: {result['count']}ê°œ")
            >>> else:
            >>>     print(f"ê²€ì¦ ì‹¤íŒ¨: {result['errors']}")
        """
        errors = []
        
        try:
            df = pd.read_csv(filepath)
            
            # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
            missing = [col for col in required if col not in df.columns]
            if missing:
                errors.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
                return {
                    'valid': False,
                    'errors': errors,
                    'count': 0,
                    'start_date': '',
                    'end_date': ''
                }
            
            # 2. ë°ì´í„° íƒ€ì… í™•ì¸
            if df['timestamp'].dtype not in ['int64', 'int32']:
                errors.append(f"íƒ€ì„ìŠ¤íƒ¬í”„ íƒ€ì… ì˜¤ë¥˜: {df['timestamp'].dtype}")
            
            for col in ['open', 'high', 'low', 'close', 'volume']:
                if df[col].dtype != 'float64':
                    errors.append(f"{col} íƒ€ì… ì˜¤ë¥˜: {df[col].dtype}")
            
            # 3. ë…¼ë¦¬ ê²€ì¦
            if not (df['high'] >= df['low']).all():
                errors.append("high < lowì¸ ìº”ë“¤ ì¡´ì¬")
            
            if not (df['high'] >= df['open']).all():
                errors.append("high < openì¸ ìº”ë“¤ ì¡´ì¬")
            
            if not (df['high'] >= df['close']).all():
                errors.append("high < closeì¸ ìº”ë“¤ ì¡´ì¬")
            
            if not (df['low'] <= df['open']).all():
                errors.append("low > openì¸ ìº”ë“¤ ì¡´ì¬")
            
            if not (df['low'] <= df['close']).all():
                errors.append("low > closeì¸ ìº”ë“¤ ì¡´ì¬")
            
            # 4. ì‹œê°„ ìˆœì„œ í™•ì¸
            if not df['timestamp'].is_monotonic_increasing:
                errors.append("íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœì„œ ì˜¤ë¥˜")
            
            # 5. ë‚ ì§œ ë²”ìœ„
            start_date = datetime.fromtimestamp(df['timestamp'].min()).strftime('%Y-%m-%d')
            end_date = datetime.fromtimestamp(df['timestamp'].max()).strftime('%Y-%m-%d')
            
            if errors:
                return {
                    'valid': False,
                    'errors': errors,
                    'count': len(df),
                    'start_date': start_date,
                    'end_date': end_date
                }
            
            return {
                'valid': True,
                'errors': [],
                'count': len(df),
                'start_date': start_date,
                'end_date': end_date
            }
        
        except Exception as e:
            return {
                'valid': False,
                'errors': [str(e)],
                'count': 0,
                'start_date': '',
                'end_date': ''
            }
    
    def load_historical_data(
        self,
        symbol: str,
        timeframe: str = '5m'
    ) -> pd.DataFrame:
        """
        CSV íŒŒì¼ ë¡œë“œ
        
        Args:
            symbol: 'DOGE/USDT', 'SOL/USDT'
            timeframe: '1m', '5m', '15m', '1h', '1d'
        
        Returns:
            pd.DataFrame: OHLCV ë°ì´í„°
        
        í˜¸ì¶œ:
            engine/backtest_engine.py
        
        Example:
            >>> manager = HistoricalDataManager()
            >>> df = manager.load_historical_data('DOGE/USDT', '5m')
            >>> print(f"ë¡œë“œë¨: {len(df)}ê°œ ìº”ë“¤")
            >>> print(df.head())
        """
        filename = f"{symbol.replace('/', '_')}_{timeframe}.csv"
        filepath = self.data_dir / filename
        
        if not filepath.exists():
            raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {filepath}")
        
        df = pd.read_csv(filepath)
        
        # ê²€ì¦
        result = self.validate_csv(filepath)
        if not result['valid']:
            raise ValueError(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {result['errors']}")
        
        return df
    
    def get_available_data(self) -> List[Dict]:
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ëª©ë¡
        
        Returns:
            [{
                'symbol': 'DOGE/USDT',
                'timeframe': '5m',
                'filename': 'DOGE_USDT_5m.csv',
                'count': 51840,
                'start_date': '2024-07-15',
                'end_date': '2025-01-15'
            }, ...]
        
        Example:
            >>> manager = HistoricalDataManager()
            >>> data_list = manager.get_available_data()
            >>> for data in data_list:
            >>>     print(f"{data['symbol']} {data['timeframe']}: {data['count']}ê°œ")
        """
        result = []
        
        for filepath in self.data_dir.glob('*.csv'):
            # íŒŒì¼ëª… íŒŒì‹± (ì˜ˆ: DOGE_USDT_5m.csv)
            parts = filepath.stem.split('_')
            if len(parts) >= 3:
                symbol = f"{parts[0]}/{parts[1]}"
                timeframe = parts[2]
                
                # ê²€ì¦
                validation = self.validate_csv(filepath)
                
                result.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'filename': filepath.name,
                    'count': validation['count'],
                    'start_date': validation['start_date'],
                    'end_date': validation['end_date'],
                    'valid': validation['valid']
                })
        
        return result
```

---

## ğŸ“ storage/cache_manager.py â­ ì‹ ê·œ

### êµ¬í˜„ ì½”ë“œ (ì „ì²´ ì‹ ê·œ)

```python
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional
from core.constants import CACHE_DIR


class CacheManager:
    """
    1ë¶„ê°„ ìœ íš¨í•œ API ì‘ë‹µ ìºì‹œ
    
    â­ ì‹ ê·œ ëª¨ë“ˆ: ë©”ëª¨ë¦¬ + íŒŒì¼ ìºì‹œ ê´€ë¦¬
    """
    
    def __init__(self, cache_ttl: int = 60):
        """
        ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            cache_ttl: ìºì‹œ ìœ íš¨ ì‹œê°„ (ì´ˆ, ê¸°ë³¸ 60ì´ˆ)
        
        í˜¸ì¶œ:
            data/fetcher.py
            indicators/calculator.py
        """
        self.cache_ttl = cache_ttl
        self.cache_dir = Path(CACHE_DIR)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ë©”ëª¨ë¦¬ ìºì‹œ (ë¹ ë¥¸ ì ‘ê·¼)
        self.memory_cache = {}
    
    def get(
        self,
        cache_type: str,
        key: str
    ) -> Optional[Dict]:
        """
        ìºì‹œ ì¡°íšŒ
        
        Args:
            cache_type: 'market_data', 'indicators'
            key: 'DOGE/USDT', 'SOL/USDT'
        
        Returns:
            Dict or None: ìºì‹œëœ ë°ì´í„° (ë§Œë£Œ ì‹œ None)
        
        í˜¸ì¶œ:
            data/fetcher.py - ì‹œì„¸ ì¡°íšŒ ì „
        
        Example:
            >>> cache = CacheManager()
            >>> data = cache.get('market_data', 'DOGE/USDT')
            >>> if data:
            >>>     print("ìºì‹œ hit!")
            >>> else:
            >>>     print("ìºì‹œ miss, API í˜¸ì¶œ í•„ìš”")
        """
        cache_key = f"{cache_type}:{key}"
        
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
        if cache_key in self.memory_cache:
            cached = self.memory_cache[cache_key]
            
            # ë§Œë£Œ í™•ì¸
            if cached['expires_at'] > time.time():
                return cached['data']
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.memory_cache[cache_key]
        
        # 2. íŒŒì¼ ìºì‹œ í™•ì¸ (ë©”ëª¨ë¦¬ miss ì‹œ)
        filepath = self.cache_dir / f"{cache_type}.json"
        
        if filepath.exists():
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    file_cache = json.load(f)
                
                if key in file_cache:
                    cached = file_cache[key]
                    
                    if cached['expires_at'] > time.time():
                        # ë©”ëª¨ë¦¬ì—ë„ ì €ì¥ (ë‹¤ìŒë²ˆ ë¹ ë¥¸ ì ‘ê·¼)
                        self.memory_cache[cache_key] = cached
                        return cached['data']
            
            except (json.JSONDecodeError, KeyError):
                pass
        
        return None
    
    def set(
        self,
        cache_type: str,
        key: str,
        data: Dict
    ) -> None:
        """
        ìºì‹œ ì €ì¥
        
        Args:
            cache_type: 'market_data', 'indicators'
            key: 'DOGE/USDT', 'SOL/USDT'
            data: ìºì‹œí•  ë°ì´í„°
        
        í˜¸ì¶œ:
            data/fetcher.py - API í˜¸ì¶œ í›„
        
        Example:
            >>> cache = CacheManager()
            >>> cache.set('market_data', 'DOGE/USDT', {
            ...     'price': 0.3821,
            ...     'volume_24h': 1234567890
            ... })
        """
        cache_key = f"{cache_type}:{key}"
        expires_at = time.time() + self.cache_ttl
        
        cached_data = {
            'data': data,
            'timestamp': time.time(),
            'expires_at': expires_at
        }
        
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥
        self.memory_cache[cache_key] = cached_data
        
        # 2. íŒŒì¼ ìºì‹œ ì €ì¥
        filepath = self.cache_dir / f"{cache_type}.json"
        
        try:
            # ê¸°ì¡´ íŒŒì¼ ë¡œë“œ
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    file_cache = json.load(f)
            else:
                file_cache = {}
            
            # ì—…ë°ì´íŠ¸
            file_cache[key] = cached_data
            
            # ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(file_cache, f, indent=2)
        
        except Exception as e:
            print(f"ìºì‹œ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def clear(self, cache_type: str = None) -> None:
        """
        ìºì‹œ ì‚­ì œ
        
        Args:
            cache_type: íŠ¹ì • íƒ€ì…ë§Œ ì‚­ì œ (Noneì´ë©´ ì „ì²´)
        
        Example:
            >>> cache = CacheManager()
            >>> cache.clear('market_data')  # market_dataë§Œ ì‚­ì œ
            >>> cache.clear()  # ì „ì²´ ì‚­ì œ
        """
        if cache_type:
            # íŠ¹ì • íƒ€ì…ë§Œ ì‚­ì œ
            keys_to_delete = [
                k for k in self.memory_cache.keys()
                if k.startswith(f"{cache_type}:")
            ]
            for key in keys_to_delete:
                del self.memory_cache[key]
            
            # íŒŒì¼ ì‚­ì œ
            filepath = self.cache_dir / f"{cache_type}.json"
            if filepath.exists():
                filepath.unlink()
        
        else:
            # ì „ì²´ ì‚­ì œ
            self.memory_cache.clear()
            
            for filepath in self.cache_dir.glob('*.json'):
                filepath.unlink()
    
    def get_stats(self) -> Dict:
        """
        ìºì‹œ í†µê³„
        
        Returns:
            {
                'memory_size': ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸°,
                'file_count': íŒŒì¼ ìºì‹œ ê°œìˆ˜,
                'total_keys': ì „ì²´ í‚¤ ìˆ˜
            }
        
        Example:
            >>> cache = CacheManager()
            >>> stats = cache.get_stats()
            >>> print(f"ìºì‹œëœ í•­ëª©: {stats['total_keys']}ê°œ")
        """
        file_count = len(list(self.cache_dir.glob('*.json')))
        
        return {
            'memory_size': len(self.memory_cache),
            'file_count': file_count,
            'total_keys': len(self.memory_cache)
        }
```

---

## ğŸ“ storage/state_manager.py â­ ì‹ ê·œ

### êµ¬í˜„ ì½”ë“œ (ì „ì²´ ì‹ ê·œ)

```python
import json
import time
from pathlib import Path
from typing import Dict, Optional
from datetime import datetime


class SystemStateManager:
    """
    ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥ ë° ë³µêµ¬
    
    â­ ì‹ ê·œ ëª¨ë“ˆ: ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ ìƒíƒœ ë³µêµ¬
    """
    
    def __init__(self, state_file: str = 'storage/system_state.json'):
        """
        ìƒíƒœ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            state_file: ìƒíƒœ íŒŒì¼ ê²½ë¡œ
        
        í˜¸ì¶œ:
            engine/base_engine.py
        """
        self.state_file = Path(state_file)
        self.state_file.parent.mkdir(parents=True, exist_ok=True)
    
    def save_state(self, state: Dict) -> bool:
        """
        ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥
        
        Args:
            state: {
                'timestamp': float,
                'mode': str,
                'balance': float,
                'positions': Dict,
                'risk_state': Dict,
                'config': Dict
            }
        
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        
        í˜¸ì¶œ:
            engine/base_engine.py - 5ë¶„ë§ˆë‹¤ ìë™
        
        Example:
            >>> manager = SystemStateManager()
            >>> success = manager.save_state({
            ...     'timestamp': time.time(),
            ...     'balance': 1050000,
            ...     'positions': {'DOGE/USDT': {...}},
            ...     'risk_state': {...}
            ... })
        """
        try:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            state['last_updated'] = datetime.now().isoformat()
            
            # ì €ì¥
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
            
            return True
        
        except Exception as e:
            print(f"âŒ ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_state(self) -> Optional[Dict]:
        """
        ì‹œìŠ¤í…œ ìƒíƒœ ë¡œë“œ
        
        Returns:
            Dict or None: ì €ì¥ëœ ìƒíƒœ
        
        í˜¸ì¶œ:
            engine/base_engine.py - ì¬ì‹œì‘ ì‹œ
        
        Example:
            >>> manager = SystemStateManager()
            >>> state = manager.load_state()
            >>> if state:
            >>>     print(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {state['last_updated']}")
            >>>     print(f"ì—´ë¦° í¬ì§€ì…˜: {len(state['positions'])}ê°œ")
        """
        if not self.state_file.exists():
            return None
        
        try:
            with open(self.state_file, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            return state
        
        except (json.JSONDecodeError, KeyError) as e:
            print(f"âŒ ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def restore_positions(
        self,
        state: Dict
    ) -> Dict[str, Dict]:
        """
        í¬ì§€ì…˜ ë³µêµ¬
        
        Args:
            state: load_state()ë¡œ ë¡œë“œí•œ ìƒíƒœ
        
        Returns:
            {
                'DOGE/USDT': {
                    'trade_id': 123,
                    'entry_price': 0.3821,
                    'quantity': 1006,
                    'entry_time': 1640000000
                },
                ...
            }
        
        í˜¸ì¶œ:
            engine/base_engine.py - initialize()
        
        Example:
            >>> manager = SystemStateManager()
            >>> state = manager.load_state()
            >>> if state:
            >>>     positions = manager.restore_positions(state)
            >>>     for symbol, pos in positions.items():
            >>>         print(f"ë³µêµ¬: {symbol} @ {pos['entry_price']}")
        """
        if not state or 'positions' not in state:
            return {}
        
        return state['positions']
    
    def clear_state(self) -> bool:
        """
        ìƒíƒœ íŒŒì¼ ì‚­ì œ
        
        í˜¸ì¶œ:
            engine/base_engine.py - ì •ìƒ ì¢…ë£Œ ì‹œ
        
        Example:
            >>> manager = SystemStateManager()
            >>> manager.clear_state()
        """
        try:
            if self.state_file.exists():
                self.state_file.unlink()
            return True
        
        except Exception as e:
            print(f"âŒ ìƒíƒœ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
```

---

## ğŸ“ storage/cleanup.py â­ ì‹ ê·œ

### êµ¬í˜„ ì½”ë“œ (ì „ì²´ ì‹ ê·œ)

```python
import os
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict


class StorageCleanup:
    """
    ìŠ¤í† ë¦¬ì§€ ì •ë¦¬ ë° ìµœì í™”
    
    â­ ì‹ ê·œ ëª¨ë“ˆ: ë””ìŠ¤í¬ ìš©ëŸ‰ ê´€ë¦¬
    """
    
    def __init__(self):
        """
        ì •ë¦¬ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        í˜¸ì¶œ:
            scripts/cleanup_storage.py
        """
        pass
    
    def cleanup_cache(self, max_age_hours: int = 1) -> Dict:
        """
        ì˜¤ë˜ëœ ìºì‹œ íŒŒì¼ ì‚­ì œ
        
        Args:
            max_age_hours: ìµœëŒ€ ë³´ê´€ ì‹œê°„ (ê¸°ë³¸ 1ì‹œê°„)
        
        Returns:
            {
                'deleted_count': ì‚­ì œëœ íŒŒì¼ ìˆ˜,
                'freed_bytes': í™•ë³´ëœ ìš©ëŸ‰ (ë°”ì´íŠ¸)
            }
        
        í˜¸ì¶œ:
            scripts/cleanup_storage.py - ë§¤ì¼ ìì •
        
        Example:
            >>> cleanup = StorageCleanup()
            >>> result = cleanup.cleanup_cache(max_age_hours=1)
            >>> print(f"ì‚­ì œ: {result['deleted_count']}ê°œ")
            >>> print(f"í™•ë³´: {result['freed_bytes']/1024/1024:.1f}MB")
        """
        from core.constants import CACHE_DIR
        
        cache_dir = Path(CACHE_DIR)
        if not cache_dir.exists():
            return {'deleted_count': 0, 'freed_bytes': 0}
        
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        cutoff_timestamp = cutoff_time.timestamp()
        
        deleted_count = 0
        freed_bytes = 0
        
        for filepath in cache_dir.glob('*.json'):
            if filepath.name == '.gitkeep':
                continue
            
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„
            mtime = os.path.getmtime(filepath)
            
            if mtime < cutoff_timestamp:
                # íŒŒì¼ í¬ê¸°
                size = filepath.stat().st_size
                
                # ì‚­ì œ
                filepath.unlink()
                
                deleted_count += 1
                freed_bytes += size
                
                print(f"ì‚­ì œ: {filepath.name}")
        
        return {
            'deleted_count': deleted_count,
            'freed_bytes': freed_bytes
        }
    
    def backup_database(self, backup_dir: str = 'storage/backups') -> bool:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
        
        Args:
            backup_dir: ë°±ì—… ë””ë ‰í† ë¦¬
        
        Returns:
            bool: ë°±ì—… ì„±ê³µ ì—¬ë¶€
        
        í˜¸ì¶œ:
            scripts/cleanup_storage.py - ë§¤ì¼ 03:00
        
        Example:
            >>> cleanup = StorageCleanup()
            >>> success = cleanup.backup_database()
            >>> if success:
            >>>     print("âœ… DB ë°±ì—… ì™„ë£Œ")
        """
        from core.constants import DB_PATH
        
        src = Path(DB_PATH)
        if not src.exists():
            print("âŒ DB íŒŒì¼ ì—†ìŒ")
            return False
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        backup_path = Path(backup_dir)
        backup_path.mkdir(parents=True, exist_ok=True)
        
        # ë‚ ì§œë³„ ë°±ì—…
        date_str = datetime.now().strftime('%Y%m%d')
        dst = backup_path / f'trades_{date_str}.db'
        
        try:
            shutil.copy2(src, dst)
            print(f"âœ… DB ë°±ì—… ì™„ë£Œ: {dst}")
            return True
        
        except Exception as e:
            print(f"âŒ DB ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
    def remove_old_backups(
        self,
        backup_dir: str = 'storage/backups',
        keep_days: int = 30
    ) -> Dict:
        """
        ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
        
        Args:
            backup_dir: ë°±ì—… ë””ë ‰í† ë¦¬
            keep_days: ë³´ê´€ ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼)
        
        Returns:
            {
                'deleted_count': ì‚­ì œëœ íŒŒì¼ ìˆ˜,
                'freed_bytes': í™•ë³´ëœ ìš©ëŸ‰ (ë°”ì´íŠ¸)
            }
        
        Example:
            >>> cleanup = StorageCleanup()
            >>> result = cleanup.remove_old_backups(keep_days=30)
            >>> print(f"ì‚­ì œ: {result['deleted_count']}ê°œ ë°±ì—…")
        """
        backup_path = Path(backup_dir)
        if not backup_path.exists():
            return {'deleted_count': 0, 'freed_bytes': 0}
        
        cutoff_time = datetime.now() - timedelta(days=keep_days)
        cutoff_timestamp = cutoff_time.timestamp()
        
        deleted_count = 0
        freed_bytes = 0
        
        for filepath in backup_path.glob('*.db'):
            mtime = os.path.getmtime(filepath)
            
            if mtime < cutoff_timestamp:
                size = filepath.stat().st_size
                
                filepath.unlink()
                
                deleted_count += 1
                freed_bytes += size
                
                print(f"ì‚­ì œ: {filepath.name}")
        
        return {
            'deleted_count': deleted_count,
            'freed_bytes': freed_bytes
        }
    
    def check_disk_space(self, min_free_gb: float = 1.0) -> Dict:
        """
        ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ í™•ì¸
        
        Args:
            min_free_gb: ìµœì†Œ í•„ìš” ê³µê°„ (GB)
        
        Returns:
            {
                'total_gb': ì „ì²´ ìš©ëŸ‰,
                'used_gb': ì‚¬ìš© ìš©ëŸ‰,
                'free_gb': ì—¬ìœ  ìš©ëŸ‰,
                'sufficient': ì¶©ë¶„ ì—¬ë¶€
            }
        
        Example:
            >>> cleanup = StorageCleanup()
            >>> space = cleanup.check_disk_space(min_free_gb=1.0)
            >>> if not space['sufficient']:
            >>>     print(f"âš ï¸ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {space['free_gb']:.1f}GB")
        """
        total, used, free = shutil.disk_usage('/')
        
        total_gb = total / (2**30)
        used_gb = used / (2**30)
        free_gb = free / (2**30)
        
        sufficient = free_gb >= min_free_gb
        
        return {
            'total_gb': round(total_gb, 2),
            'used_gb': round(used_gb, 2),
            'free_gb': round(free_gb, 2),
            'sufficient': sufficient
        }
    
    def get_storage_summary(self) -> Dict:
        """
        ìŠ¤í† ë¦¬ì§€ ìš”ì•½ ì •ë³´
        
        Returns:
            {
                'historical': {
                    'count': íŒŒì¼ ìˆ˜,
                    'size_mb': ìš©ëŸ‰ (MB)
                },
                'cache': {...},
                'database': {...},
                'backups': {...},
                'total_mb': ì „ì²´ ìš©ëŸ‰
            }
        
        Example:
            >>> cleanup = StorageCleanup()
            >>> summary = cleanup.get_storage_summary()
            >>> print(f"Historical: {summary['historical']['size_mb']:.1f}MB")
            >>> print(f"Total: {summary['total_mb']:.1f}MB")
        """
        from core.constants import HISTORICAL_DATA_DIR, CACHE_DIR, DB_PATH
        
        result = {}
        total_size = 0
        
        # Historical
        hist_dir = Path(HISTORICAL_DATA_DIR)
        if hist_dir.exists():
            files = list(hist_dir.glob('*.csv'))
            size = sum(f.stat().st_size for f in files)
            result['historical'] = {
                'count': len(files),
                'size_mb': round(size / (1024**2), 2)
            }
            total_size += size
        
        # Cache
        cache_dir = Path(CACHE_DIR)
        if cache_dir.exists():
            files = list(cache_dir.glob('*.json'))
            size = sum(f.stat().st_size for f in files)
            result['cache'] = {
                'count': len(files),
                'size_mb': round(size / (1024**2), 2)
            }
            total_size += size
        
        # Database
        db_path = Path(DB_PATH)
        if db_path.exists():
            size = db_path.stat().st_size
            result['database'] = {
                'size_mb': round(size / (1024**2), 2)
            }
            total_size += size
        
        # Backups
        backup_dir = Path('storage/backups')
        if backup_dir.exists():
            files = list(backup_dir.glob('*.db'))
            size = sum(f.stat().st_size for f in files)
            result['backups'] = {
                'count': len(files),
                'size_mb': round(size / (1024**2), 2)
            }
            total_size += size
        
        result['total_mb'] = round(total_size / (1024**2), 2)
        
        return result
```

---

## ğŸ“ core/constants.py ì¶”ê°€ í•„ìš” â­

### êµ¬í˜„ ì½”ë“œ (ì¶”ê°€)

```python
# core/constants.pyì— ì¶”ê°€

from pathlib import Path

# â­ Storage ê²½ë¡œ
STORAGE_DIR = Path('storage')
HISTORICAL_DATA_DIR = STORAGE_DIR / 'historical'
CACHE_DIR = STORAGE_DIR / 'cache'
DB_PATH = STORAGE_DIR / 'trades.db'
```

---

## ì „ì²´ ì˜ì¡´ì„± ê·¸ë˜í”„

```
storage/historical_manager.py â­
â”œâ”€â”€ ì‚¬ìš©: ccxt, pandas, core/constants
â””â”€â”€ ì‚¬ìš©ì²˜: scripts/download_historical_data.py, engine/backtest_engine.py

storage/cache_manager.py â­
â”œâ”€â”€ ì‚¬ìš©: json, time, core/constants
â””â”€â”€ ì‚¬ìš©ì²˜: data/fetcher.py, indicators/calculator.py

storage/state_manager.py â­
â”œâ”€â”€ ì‚¬ìš©: json, datetime
â””â”€â”€ ì‚¬ìš©ì²˜: engine/base_engine.py

storage/cleanup.py â­
â”œâ”€â”€ ì‚¬ìš©: os, shutil, core/constants
â””â”€â”€ ì‚¬ìš©ì²˜: scripts/cleanup_storage.py
```

---

## ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ

### ì˜ˆì œ 1: ê³¼ê±° ë°ì´í„° ë‹¤ìš´ë¡œë“œ

```python
from storage import HistoricalDataManager

# ë§¤ë‹ˆì € ì´ˆê¸°í™”
manager = HistoricalDataManager()

# DOGE ë°ì´í„° ë‹¤ìš´ë¡œë“œ (6ê°œì›”, 5ë¶„ë´‰)
success = manager.download_historical_data(
    symbol='DOGE/USDT',
    timeframe='5m',
    days=180
)

if success:
    # ê²€ì¦
    result = manager.validate_csv('storage/historical/DOGE_USDT_5m.csv')
    if result['valid']:
        print(f"âœ… ê²€ì¦ ì„±ê³µ: {result['count']}ê°œ")
        print(f"ê¸°ê°„: {result['start_date']} ~ {result['end_date']}")
    else:
        print(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {result['errors']}")
```

### ì˜ˆì œ 2: ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ

```python
from storage import HistoricalDataManager
from engine import BacktestEngine

class BacktestEngine:
    def __init__(self, config, exchange):
        self.data_manager = HistoricalDataManager()
    
    async def initialize(self):
        # ê³¼ê±° ë°ì´í„° ë¡œë“œ
        self.doge_data = self.data_manager.load_historical_data(
            'DOGE/USDT',
            '5m'
        )
        
        self.sol_data = self.data_manager.load_historical_data(
            'SOL/USDT',
            '5m'
        )
        
        print(f"âœ… DOGE: {len(self.doge_data)}ê°œ ìº”ë“¤")
        print(f"âœ… SOL: {len(self.sol_data)}ê°œ ìº”ë“¤")
```

### ì˜ˆì œ 3: ìºì‹œ ì‚¬ìš©

```python
from storage import CacheManager
from data import MarketDataFetcher

class MarketDataFetcher:
    def __init__(self, exchange):
        self.exchange = exchange
        self.cache = CacheManager(cache_ttl=60)
    
    async def fetch_ticker(self, symbol):
        # ìºì‹œ í™•ì¸
        cached = self.cache.get('market_data', symbol)
        if cached:
            print(f"âœ… ìºì‹œ hit: {symbol}")
            return cached
        
        # API í˜¸ì¶œ
        print(f"ğŸ”„ API í˜¸ì¶œ: {symbol}")
        data = await self.exchange.fetch_ticker(symbol)
        
        # ìºì‹œ ì €ì¥
        self.cache.set('market_data', symbol, data)
        
        return data
```

### ì˜ˆì œ 4: ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥/ë³µêµ¬

```python
from storage import SystemStateManager

class BaseEngine:
    def __init__(self, config, exchange):
        self.state_manager = SystemStateManager()
    
    async def initialize(self):
        # ìƒíƒœ ë³µêµ¬ ì‹œë„
        state = self.state_manager.load_state()
        
        if state:
            print("ğŸ”„ ì´ì „ ìƒíƒœ ë°œê²¬, ë³µêµ¬ ì‹œë„...")
            
            # í¬ì§€ì…˜ ë³µêµ¬
            positions = self.state_manager.restore_positions(state)
            
            for symbol, pos in positions.items():
                self.positions[symbol] = pos
                print(f"âœ… ë³µêµ¬: {symbol} @ {pos['entry_price']}")
        
        else:
            print("ğŸ†• ìƒˆë¡œìš´ ì‹œì‘")
    
    async def save_state_periodically(self):
        """5ë¶„ë§ˆë‹¤ ìƒíƒœ ì €ì¥"""
        while self.running:
            state = {
                'timestamp': time.time(),
                'mode': self.config.MODE,
                'balance': self.exchange.get_balance()['total_krw'],
                'positions': self.positions,
                'risk_state': self.risk_manager.get_state()
            }
            
            self.state_manager.save_state(state)
            
            await asyncio.sleep(300)
    
    def cleanup(self):
        """ì •ìƒ ì¢…ë£Œ ì‹œ ìƒíƒœ ì‚­ì œ"""
        self.state_manager.clear_state()
        print("âœ… ìƒíƒœ íŒŒì¼ ì‚­ì œ")
```

### ì˜ˆì œ 5: ìŠ¤í† ë¦¬ì§€ ì •ë¦¬

```python
# scripts/cleanup_storage.py
from storage import StorageCleanup

def main():
    cleanup = StorageCleanup()
    
    print("ğŸ§¹ ìŠ¤í† ë¦¬ì§€ ì •ë¦¬ ì‹œì‘...")
    
    # 1. ìºì‹œ ì •ë¦¬
    result = cleanup.cleanup_cache(max_age_hours=1)
    print(f"âœ… ìºì‹œ ì •ë¦¬: {result['deleted_count']}ê°œ")
    
    # 2. DB ë°±ì—…
    success = cleanup.backup_database()
    if success:
        print("âœ… DB ë°±ì—… ì™„ë£Œ")
    
    # 3. ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
    result = cleanup.remove_old_backups(keep_days=30)
    print(f"âœ… ë°±ì—… ì •ë¦¬: {result['deleted_count']}ê°œ")
    
    # 4. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
    space = cleanup.check_disk_space(min_free_gb=1.0)
    print(f"ğŸ’¾ ì—¬ìœ  ê³µê°„: {space['free_gb']:.1f}GB")
    
    if not space['sufficient']:
        print("âš ï¸ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±!")
    
    # 5. ìš”ì•½
    summary = cleanup.get_storage_summary()
    print("\nğŸ“Š ìŠ¤í† ë¦¬ì§€ ìš”ì•½:")
    print(f"  Historical: {summary['historical']['size_mb']:.1f}MB")
    print(f"  Cache: {summary['cache']['size_mb']:.1f}MB")
    print(f"  Database: {summary['database']['size_mb']:.1f}MB")
    print(f"  Backups: {summary['backups']['size_mb']:.1f}MB")
    print(f"  Total: {summary['total_mb']:.1f}MB")
    
    print("\nâœ… ìŠ¤í† ë¦¬ì§€ ì •ë¦¬ ì™„ë£Œ")

if __name__ == '__main__':
    main()
```

---

## í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### historical_manager.py í…ŒìŠ¤íŠ¸

```python
import pytest
from storage import HistoricalDataManager
import pandas as pd

def test_download_data():
    """ë°ì´í„° ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    manager = HistoricalDataManager()
    
    # ì§§ì€ ê¸°ê°„ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    success = manager.download_historical_data(
        'DOGE/USDT',
        '1h',
        days=7
    )
    
    assert success
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    filepath = manager.data_dir / 'DOGE_USDT_1h.csv'
    assert filepath.exists()

def test_validate_csv():
    """CSV ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    manager = HistoricalDataManager()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        'timestamp': [1640000000, 1640000300],
        'open': [100.0, 101.0],
        'high': [105.0, 106.0],
        'low': [98.0, 99.0],
        'close': [102.0, 103.0],
        'volume': [1000000, 1100000]
    })
    
    test_file = manager.data_dir / 'test.csv'
    test_data.to_csv(test_file, index=False)
    
    # ê²€ì¦
    result = manager.validate_csv(test_file)
    
    assert result['valid']
    assert result['count'] == 2
    
    # ì •ë¦¬
    test_file.unlink()

def test_get_available_data():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ëª©ë¡ í…ŒìŠ¤íŠ¸"""
    manager = HistoricalDataManager()
    
    data_list = manager.get_available_data()
    
    assert isinstance(data_list, list)
    
    if data_list:
        assert 'symbol' in data_list[0]
        assert 'timeframe' in data_list[0]
```

### cache_manager.py í…ŒìŠ¤íŠ¸

```python
def test_cache_set_get():
    """ìºì‹œ ì €ì¥/ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    cache = CacheManager(cache_ttl=2)
    
    # ì €ì¥
    cache.set('test', 'key1', {'value': 123})
    
    # ì¡°íšŒ
    data = cache.get('test', 'key1')
    assert data is not None
    assert data['value'] == 123
    
    # ë§Œë£Œ í›„ ì¡°íšŒ
    import time
    time.sleep(3)
    
    data = cache.get('test', 'key1')
    assert data is None

def test_cache_clear():
    """ìºì‹œ ì‚­ì œ í…ŒìŠ¤íŠ¸"""
    cache = CacheManager()
    
    cache.set('test', 'key1', {'value': 1})
    cache.set('test', 'key2', {'value': 2})
    
    # ì‚­ì œ
    cache.clear('test')
    
    assert cache.get('test', 'key1') is None
    assert cache.get('test', 'key2') is None
```

### state_manager.py í…ŒìŠ¤íŠ¸

```python
def test_save_load_state():
    """ìƒíƒœ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    manager = SystemStateManager('test_state.json')
    
    # ì €ì¥
    state = {
        'timestamp': time.time(),
        'balance': 1000000,
        'positions': {
            'DOGE/USDT': {
                'entry_price': 0.3821,
                'quantity': 1000
            }
        }
    }
    
    success = manager.save_state(state)
    assert success
    
    # ë¡œë“œ
    loaded = manager.load_state()
    assert loaded is not None
    assert loaded['balance'] == 1000000
    
    # ì •ë¦¬
    manager.clear_state()
```

### cleanup.py í…ŒìŠ¤íŠ¸

```python
def test_backup_database():
    """DB ë°±ì—… í…ŒìŠ¤íŠ¸"""
    cleanup = StorageCleanup()
    
    success = cleanup.backup_database('test_backups')
    
    if success:
        # ë°±ì—… íŒŒì¼ ì¡´ì¬ í™•ì¸
        from datetime import datetime
        date_str = datetime.now().strftime('%Y%m%d')
        backup_file = Path(f'test_backups/trades_{date_str}.db')
        assert backup_file.exists()
        
        # ì •ë¦¬
        backup_file.unlink()

def test_check_disk_space():
    """ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ í…ŒìŠ¤íŠ¸"""
    cleanup = StorageCleanup()
    
    space = cleanup.check_disk_space()
    
    assert 'total_gb' in space
    assert 'free_gb' in space
    assert 'sufficient' in space
    assert space['total_gb'] > 0
```

---

## ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### core/constants.py â­
- [x] â­ STORAGE_DIR ì¶”ê°€
- [x] â­ HISTORICAL_DATA_DIR ì¶”ê°€
- [x] â­ CACHE_DIR ì¶”ê°€
- [x] â­ DB_PATH ì¶”ê°€

### historical_manager.py â­
- [x] â­ HistoricalDataManager í´ë˜ìŠ¤ (ì‹ ê·œ)
- [x] â­ download_historical_data() ë©”ì„œë“œ
- [x] â­ validate_csv() ë©”ì„œë“œ
- [x] â­ load_historical_data() ë©”ì„œë“œ
- [x] â­ get_available_data() ë©”ì„œë“œ

### cache_manager.py â­
- [x] â­ CacheManager í´ë˜ìŠ¤ (ì‹ ê·œ)
- [x] â­ get() ë©”ì„œë“œ (ë©”ëª¨ë¦¬ + íŒŒì¼)
- [x] â­ set() ë©”ì„œë“œ (ë©”ëª¨ë¦¬ + íŒŒì¼)
- [x] â­ clear() ë©”ì„œë“œ
- [x] â­ get_stats() ë©”ì„œë“œ

### state_manager.py â­
- [x] â­ SystemStateManager í´ë˜ìŠ¤ (ì‹ ê·œ)
- [x] â­ save_state() ë©”ì„œë“œ
- [x] â­ load_state() ë©”ì„œë“œ
- [x] â­ restore_positions() ë©”ì„œë“œ
- [x] â­ clear_state() ë©”ì„œë“œ

### cleanup.py â­
- [x] â­ StorageCleanup í´ë˜ìŠ¤ (ì‹ ê·œ)
- [x] â­ cleanup_cache() ë©”ì„œë“œ
- [x] â­ backup_database() ë©”ì„œë“œ
- [x] â­ remove_old_backups() ë©”ì„œë“œ
- [x] â­ check_disk_space() ë©”ì„œë“œ
- [x] â­ get_storage_summary() ë©”ì„œë“œ

---

## ì£¼ìš” íŠ¹ì§•

### 1. ê³¼ê±° ë°ì´í„° ê´€ë¦¬ â­
- Bybit API ìë™ ë‹¤ìš´ë¡œë“œ
- CSV í˜•ì‹ ìë™ ê²€ì¦
- ë°±í…ŒìŠ¤íŠ¸ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥

### 2. ìºì‹œ ì‹œìŠ¤í…œ â­
- ë©”ëª¨ë¦¬ + íŒŒì¼ ì´ì¤‘ ìºì‹œ
- 1ë¶„ TTL (ì„¤ì • ê°€ëŠ¥)
- API í˜¸ì¶œ ìµœì†Œí™”

### 3. ìƒíƒœ ì €ì¥/ë³µêµ¬ â­
- 5ë¶„ë§ˆë‹¤ ìë™ ì €ì¥
- ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ ë³µêµ¬
- í¬ì§€ì…˜ ë¬´ì†ì‹¤ ë³µêµ¬

### 4. ìë™ ì •ë¦¬ â­
- ì˜¤ë˜ëœ ìºì‹œ ì‚­ì œ
- DB ìë™ ë°±ì—…
- ë””ìŠ¤í¬ ê³µê°„ ëª¨ë‹ˆí„°ë§

### 5. ì‹¤ì „ ì¤‘ì‹¬ ì„¤ê³„ â­
- í•¨ìˆ˜ ëª…ì„¸ì„œ í˜•íƒœ
- ì‹¤ì œ êµ¬í˜„ ê°€ëŠ¥
- í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ í¬í•¨

---

**ë¬¸ì„œ ë²„ì „**: v2.0 (ê°œì„ íŒ)  
**ì‘ì„±ì¼**: 2025-01-22  
**ê°œì„ ì‚¬í•­**:
- â­ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ëª…ì„œ â†’ í•¨ìˆ˜ ëª…ì„¸ì„œë¡œ ì™„ì „ ë³€í™˜
- â­ historical_manager.py ì‹ ê·œ ì¶”ê°€ (ê³¼ê±° ë°ì´í„° ê´€ë¦¬)
- â­ cache_manager.py ì‹ ê·œ ì¶”ê°€ (ìºì‹œ ê´€ë¦¬)
- â­ state_manager.py ì‹ ê·œ ì¶”ê°€ (ìƒíƒœ ì €ì¥/ë³µêµ¬)
- â­ cleanup.py ì‹ ê·œ ì¶”ê°€ (ìŠ¤í† ë¦¬ì§€ ì •ë¦¬)
- â­ core/constants.py ê²½ë¡œ ìƒìˆ˜ ì¶”ê°€
- âœ… ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ 5ê°œ
- âœ… í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì™„ì„±

**ê²€ì¦ ìƒíƒœ**: âœ… ì™„ë£Œ
